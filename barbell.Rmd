---
title: "Barbell Lift Classification"
author: "Michael Ching"
date: "January 17, 2015"
output: html_document
---

# Summary
This manuscript describes the process of classifying barbell lifts into different categories based on automated sensor data. A machine learning model was created using the random forests algorithm. Accuracy approached 100%, and the out of sample error rate was estimated to be 0.1%. 

# Data Source
Data were collected by Velloso et al. (2013), available here: http://groupware.les.inf.puc-rio.br/har. I downloaded the data from the Coursera links as below.

```{r, cache=TRUE}
library(RCurl)
url_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
timestamp()
x <- getURL(url_train)
train <- read.csv(textConnection(x), na.strings = c("NA", "#DIV/0!"))
x <- getURL(url_test)
test <- read.csv(textConnection(x), na.strings = c("NA", "#DIV/0!"))
rm(x)
```

# Exploring Data 
The full training data set contained `r nrow(train)` observations on `r ncol(train)` variables. The test data set contained `r nrow(test)` observations. The names of the features are listed below.

```{r}
library(caret); library(randomForest)
names(train)
```

# Data Processing
I split the provided training data into training and validation samples.
```{r}
set.seed(1234)
inTrain <- createDataPartition(y=train$classe, p=0.7, list=FALSE)
train <- train[inTrain,]
probe <- train[-inTrain,]
```

Because I planned to use random forests as a non-parametric method of creating a classification model, I assessed for the presence of "NA" observations and other observations that would not be handled appropriately by this algorithm. In most of the variables in which there were "NA", the "NA" values constituted the vast majority of the observations, and imputation would not be appropriate. I elected to remove these from the training data. 
```{r}
train_no_NAs <- sapply(train, function(x) !any(is.na(x)))
train_complete <- train[, train_no_NAs]
```

# Model Creation
To create the classification model, I used the `randomForest` procedure from the `randomForest` package. I elected not to use the first 7 features since they did not contain data that I felt would be relevant to prediction. That is, the row number, timestamps, subject ID, and whether it was the first observation of a new window of observations.
```{r, cache = TRUE}
set.seed(96825)
modfit <- randomForest(classe ~ ., data = train_complete[, -(1:7)])
```

# Cross Validation and Estimating Out of Sample Error Rate
The estimate of out of sample error rate is calculated internally via bootstrapping. That is, each tree is constructed from a random sample of the data (approximately 2/3 of the data). Each of the remaining left-out observations are predicted using the tree, and the probability of being in the most common "out of bag" category after the model is complete results in the out-of-bag error estimate of .

```{r}
print(modfit)
```

```{r}
# Error rate in training data
predtrain <- predict(modfit, train_complete)
confusionMatrix(predtrain, train_complete$classe)

# Error rate in validation data
predprobe <- predict(modfit, probe)
confusionMatrix(predtrain, train_complete$classe)
```

Predictions on test data
```{r}
predtest <- predict(modfit, test)
print(predtest)
```